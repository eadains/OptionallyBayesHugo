<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>Simulation of Stochastic Processes | Optionally Bayes</title>
<meta name="keywords" content="stochastic-processes, monte-carlo, python">
<meta name="description" content="Simulating Brownian Motion and two common stochastic processes.">
<meta name="author" content="Erik Dains">
<link rel="canonical" href="http://eadains.github.io/OptionallyBayesHugo/posts/stoch_proc/">
<link crossorigin="anonymous" href="/OptionallyBayesHugo/assets/css/stylesheet.bcfc03792d6caa596ec2d6e8f4e36ba32f6840d6e52e04254b294666b3f67ad2.css" integrity="sha256-vPwDeS1sqlluwtbo9ONroy9oQNblLgQlSylGZrP2etI=" rel="preload stylesheet" as="style">
<link rel="icon" href="http://eadains.github.io/OptionallyBayesHugo/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="http://eadains.github.io/OptionallyBayesHugo/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="http://eadains.github.io/OptionallyBayesHugo/favicon-32x32.png">
<link rel="apple-touch-icon" href="http://eadains.github.io/OptionallyBayesHugo/apple-touch-icon.png">
<link rel="mask-icon" href="http://eadains.github.io/OptionallyBayesHugo/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="en" href="http://eadains.github.io/OptionallyBayesHugo/posts/stoch_proc/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
</noscript>
<script>
    MathJax = {
        tex: {
            inlineMath: [['$', '$'], ['\\(', '\\)']]
        }
    };
</script>
<script type="text/javascript" id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-svg.js">
</script>

  

<meta property="og:title" content="Simulation of Stochastic Processes" />
<meta property="og:description" content="Simulating Brownian Motion and two common stochastic processes." />
<meta property="og:type" content="article" />
<meta property="og:url" content="http://eadains.github.io/OptionallyBayesHugo/posts/stoch_proc/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-02-10T00:00:00+00:00" />
<meta property="article:modified_time" content="2023-02-10T00:00:00+00:00" />

<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Simulation of Stochastic Processes"/>
<meta name="twitter:description" content="Simulating Brownian Motion and two common stochastic processes."/>


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Posts",
      "item": "http://eadains.github.io/OptionallyBayesHugo/posts/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "Simulation of Stochastic Processes",
      "item": "http://eadains.github.io/OptionallyBayesHugo/posts/stoch_proc/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "Simulation of Stochastic Processes",
  "name": "Simulation of Stochastic Processes",
  "description": "Simulating Brownian Motion and two common stochastic processes.",
  "keywords": [
    "stochastic-processes", "monte-carlo", "python"
  ],
  "articleBody": "I’ve been taking a class about stochastic calculus, so in this post I want to explore some basic monte carlo simulations of Brownian Motion and two fundamental stochastic differential equations.\nBrownian Motion First, we have to simulate the fundmanetal process that drives most of stochastic calculus: Brownian Motion.\nA stochastic process $W$ is Brownian Motion if the following hold:\n$ W_0 = 0 $ $ W $ has independent increments, i.e. if $r \u003c s \\le t \u003c u$ then $W_u - W_t$ and $W_s - W_r$ are independent random variables For $s $W$ is continuous Proving that a process like this exists is possible, but very hard, especially property 4, but we will take it as given.\nSo, given these properties, how do we generate sample paths? Well let’s define $T$ to be the terminal time we want to simulate till and $n$ be the number of sample points we want to generate. Then we have a set of times $t_0 = 0 \u003c t_1 \u003c \\ldots \u003c t_{n-1} \u003c t_n=T$ where $t_n - t_{n-1} = \\frac{T}{n-1}$. So, from property (3) in the definition we know that $W_{t_n} - W_{t_{n-1}} \\sim \\mathcal{N}(0, \\frac{T}{n-1})$. If we define a set of independent random variables $Z_r \\sim \\mathcal{N}(0, \\frac{T}{n-1})$ then we can say that $W_{t_n} - W_{t_{n-1}} = Z_{t_n}$, or $W_{t_n} = Z_{t_n} + W_{t_{n-1}}$. Then using property (1) in the definition we get (taking liberties with the time subscript) that $W_0 = 0$ and $W_1 = Z_1 + W_0 = Z_1$, $W_2 = Z_1 + W_1 = Z + Z_2$, $W_3 = Z_3 + W_2 = Z_3 + Z_2 + Z_1$, and so on. In other words, $W_t$ is just a sum of independent normal random variables with $\\mu = 0$ and $\\sigma^2 = \\frac{T}{n-1}$. So, to generate $n$ samples of Brownian Motion from time $t=0$ to $t=T$ we simply need to compute the cumulative sum of $n-1$ samples from a normal distribution with $\\mu = 0$ and $\\sigma^2 = \\frac{T}{n-1}$, which is what the function below does.\nimport numpy as np import matplotlib.pyplot as plt plt.rcParams[\"figure.figsize\"] = (15,10) rng = np.random.default_rng() def BM_gen(T, n): # Variance scales with difference in time between each sample point # dividing by (n-1) because of fencepost-counting sigma_sq = T/(n-1) t = np.linspace(0, T, n) norm_sample = rng.normal(0, np.sqrt(sigma_sq), n-1) # Brownian motion assumed to start at 0 at time t=0 W_t = np.append([0], norm_sample.cumsum()) return (t, W_t) And then we can simulate a few sample paths and plot them. Note that $T=2$ and $n=1000$. As $n \\rightarrow \\infty$ the sample path converges to true continous Brownian Motion, these are all discrete approximations.\nt, bm = BM_gen(2, 1000) _, bm2 = BM_gen(2, 1000) _, bm3 = BM_gen(2, 1000) plt.plot(t, bm) plt.plot(t, bm2) plt.plot(t, bm3) plt.title(\"Brownian Motion Sample Paths\") plt.xlabel(\"Time\") plt.ylabel(\"Value\") Geometric Brownian Motion Now we move on to what is probably the most widely applied stochastic process, Geometric Brownian Motion:\n$ dX_t = \\mu X_t dt + \\sigma X_t dW_t $\n$X_0 = x_0$\nUsing methods of stochastic calculus, one can arrive at the following solution:\n$ X_t = x_0 \\exp((\\mu - \\frac{\\sigma^2}{2}) t + \\sigma W_t) $.\nWhich has expectation\n$E[X_t] = x_0 e^{\\mu t}$\nNote one important property of this solution is that it always has the same sign as the initial condition. This makes it useful for modelling stock prices as they need to be always positive.\nBecause of this simple formula, it’s very easy to simulate sample paths of Geometric Brownian Motion once you have a Brownian Motion sample path:\ndef GBM_gen(x_0, mu, sigma, T, n): t, W_t = BM_gen(T, n) X_t = x_0 * np.exp((mu - sigma**2/2) * t + sigma * W_t) return (t, X_t) And then we can again generate some sample paths and plot the expected value function:\nx_0 = 1 mu = 1 sigma = 0.4 t, gbm = GBM_gen(x_0, mu, sigma, 2, 1000) _, gbm2 = GBM_gen(x_0, mu, sigma, 2, 1000) _, gbm3 = GBM_gen(x_0, mu, sigma, 2, 1000) plt.plot(t, x_0 * np.exp(mu * t), color=\"black\") plt.plot(t, gbm) plt.plot(t, gbm2) plt.plot(t, gbm3) plt.legend([\"E(X_t)\"]) plt.title(\"Geometric Brownian Motion Sample Paths\") plt.xlabel(\"Time\") plt.ylabel(\"Value\") The Linear Stochastic Differential Equation Next is the Linear SDE:\n$dX_t = \\mu X_t dt + \\sigma dW_t$\n$X_0 = x_0$\nThis has the same drift term as GBM, but doesn’t scale it’s noise by the current value of the process. This has solution\n$ X_t = x_0 e^{\\mu t} + \\sigma \\int_{0}^{t} e^{\\mu(t-s)} dW_s $\nWith expectation\n$E[X_t] = x_0e^{\\mu t} $\nwhich we expect given the matching drift term to GBM.\nThis, unlike the GBM solution, includes a stochastic integral which must be estimated. In a similar vein to traditional Riemann–Stieltjes integrals, we can estimate stochastic integrals by\n$ \\int_{a}^{b} g_s dW_s = \\sum_{k=0}^{n-1} g_{t_k}(W_{t_{k+1}} - W_{t_k}) $\nwhere $g$ is some arbitrary function or process and each $t_k$ is a time partition like we defined in the section above on Brownian Motion. As $n \\rightarrow \\infty$ this sum converges to the integral. The function below estimates this sum given a function, a set of times, and a Brownian Motion sample path:\ndef stoch_int_est(g, t, W_t): # W_(t+1) - W_t # Duplicate last difference so that the length of this vector matches t # This is not technically correct, but is good enough forward_diff = np.append(W_t[1:] - W_t[:-1], W_t[-1] - W_t[-2]) func_vals = g(t, t[-1]) return (func_vals * forward_diff).cumsum() We can test that this function works by estimating a stochastic integral we know the solution to. The integral of Brownian Motion with respect to itself\n$ \\int_{0}^{t} W_s dW_s $\ncan be shown using Ito’s Lemma to have the solution\n$\\frac{W_t^2 - t}{2}$\nBelow, we plot a Brownian Motion sample path, the known solution of the integral of that path with respect to itself, and the estimate given by the above function:\nt, W_t = BM_gen(2, 1000) plt.plot(t, W_t) plt.plot(t, stoch_int_est(lambda s, t: W_t, t, W_t)) plt.plot(t, (W_t**2 - t)/2) plt.legend([\"W_t\", \"Est\", \"Real\"]) plt.title(\"Stochastic Integrals\") plt.xlabel(\"Time\") plt.ylabel(\"Value\") You can see the estimate and the real solutions are quite close to each other, verifying the behavior of our estimation function. As we set $n$ to larger values, the convergence will improve. Now, we can use our estimate of the stochastic integral to create sample paths of the linear SDE:\ndef linear_sde_gen(x_0, mu, sigma, T, n): t, W_t = BM_gen(T, n) X_t = x_0 * np.exp(mu * t) + sigma * stoch_int_est(lambda s, t: np.exp(mu * (t - s)), t, W_t) return t, X_t And again we can simulate some sample paths along with their expectation:\nx_0 = 1 mu = 1 sigma = 0.4 t, linear_sde = linear_sde_gen(x_0, mu, sigma, 2, 1000) _, linear_sde2 = linear_sde_gen(x_0, mu, sigma, 2, 1000) _, linear_sde3 = linear_sde_gen(x_0, mu, sigma, 2, 1000) plt.plot(t, x_0 * np.exp(mu * t), color=\"black\") plt.plot(t, linear_sde) plt.plot(t, linear_sde2) plt.plot(t, linear_sde3) plt.legend([\"E(X_t)\"]) plt.title(\"Linear SDE Sample Paths\") plt.xlabel(\"Time\") plt.ylabel(\"Value\") As compared to GBM, we can see that firstly, the values can become negative even with a positive initial condition. Secondly, because the noise doesn’t scale with the value of the process, we can see that the noise becomes smaller as time increases.\nConclusion This was a basic introduction to simulation of stochastic processes along with an example of how to estimate stochastic integrals.\nReferences Björk, T. (2020). Arbitrage theory in continuous time. Oxford University Press.\n",
  "wordCount" : "1233",
  "inLanguage": "en",
  "datePublished": "2023-02-10T00:00:00Z",
  "dateModified": "2023-02-10T00:00:00Z",
  "author":{
    "@type": "Person",
    "name": "Erik Dains"
  },
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "http://eadains.github.io/OptionallyBayesHugo/posts/stoch_proc/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Optionally Bayes",
    "logo": {
      "@type": "ImageObject",
      "url": "http://eadains.github.io/OptionallyBayesHugo/favicon.ico"
    }
  }
}
</script>
</head>

<body class="" id="top">

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="http://eadains.github.io/OptionallyBayesHugo/" accesskey="h" title="Optionally Bayes (Alt + H)">Optionally Bayes</a>
            <div class="logo-switches">
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="http://eadains.github.io/OptionallyBayesHugo/posts/" title="Posts">
                    <span>Posts</span>
                </a>
            </li>
            <li>
                <a href="http://eadains.github.io/OptionallyBayesHugo/tags/" title="Tags">
                    <span>Tags</span>
                </a>
            </li>
            <li>
                <a href="http://eadains.github.io/OptionallyBayesHugo/archives/" title="Archive">
                    <span>Archive</span>
                </a>
            </li>
            <li>
                <a href="http://eadains.github.io/OptionallyBayesHugo/search/" title="Search (Alt &#43; /)" accesskey=/>
                    <span>Search</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    
    <h1 class="post-title entry-hint-parent">
      Simulation of Stochastic Processes
    </h1>
    <div class="post-meta"><span title='2023-02-10 00:00:00 +0000 UTC'>February 10, 2023</span>&nbsp;·&nbsp;Erik Dains

</div>
  </header> 
  <div class="post-content"><p>I&rsquo;ve been taking a class about stochastic calculus, so in this post I want to explore some basic monte carlo simulations of Brownian Motion and two fundamental stochastic differential equations.</p>
<h1 id="brownian-motion">Brownian Motion<a hidden class="anchor" aria-hidden="true" href="#brownian-motion">#</a></h1>
<hr>
<p>First, we have to simulate the fundmanetal process that drives most of stochastic calculus: Brownian Motion.</p>
<blockquote>
<p>A stochastic process $W$ is Brownian Motion if the following hold:</p>
<ol>
<li>$ W_0 = 0 $</li>
<li>$ W $ has independent increments, i.e. if $r &lt; s \le t &lt; u$ then $W_u - W_t$ and $W_s - W_r$ are independent random variables</li>
<li>For $s&lt;t$ the random variable $W_t - W_s$ is normally distributed with $\mu=0$ and $\sigma^2=t-s$</li>
<li>$W$ is continuous</li>
</ol>
</blockquote>
<p>Proving that a process like this exists is possible, but very hard, especially property 4, but we will take it as given.</p>
<p>So, given these properties, how do we generate sample paths? Well let&rsquo;s define $T$ to be the terminal time we want to simulate till and $n$ be the number of sample points we want to generate. Then we have a set of times $t_0 = 0 &lt; t_1 &lt; \ldots &lt; t_{n-1} &lt; t_n=T$ where $t_n - t_{n-1} = \frac{T}{n-1}$. So, from property (3) in the definition we know that $W_{t_n} - W_{t_{n-1}} \sim \mathcal{N}(0, \frac{T}{n-1})$. If we define a set of independent random variables $Z_r \sim \mathcal{N}(0, \frac{T}{n-1})$ then we can say that $W_{t_n} - W_{t_{n-1}} = Z_{t_n}$, or $W_{t_n} = Z_{t_n} + W_{t_{n-1}}$. Then using property (1) in the definition we get (taking liberties with the time subscript) that $W_0 = 0$ and $W_1 = Z_1 + W_0 = Z_1$, $W_2 = Z_1 + W_1 = Z + Z_2$, $W_3 = Z_3 + W_2 = Z_3 + Z_2 + Z_1$, and so on. In other words, $W_t$ is just a sum of independent normal random variables with $\mu = 0$ and $\sigma^2 = \frac{T}{n-1}$. So, to generate $n$ samples of Brownian Motion from time $t=0$ to $t=T$ we simply need to compute the cumulative sum of $n-1$ samples from a normal distribution with $\mu = 0$ and $\sigma^2 = \frac{T}{n-1}$, which is what the function below does.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">import</span> numpy <span style="color:#66d9ef">as</span> np
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> matplotlib.pyplot <span style="color:#66d9ef">as</span> plt
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>rcParams[<span style="color:#e6db74">&#34;figure.figsize&#34;</span>] <span style="color:#f92672">=</span> (<span style="color:#ae81ff">15</span>,<span style="color:#ae81ff">10</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>rng <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>random<span style="color:#f92672">.</span>default_rng()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">BM_gen</span>(T, n):
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># Variance scales with difference in time between each sample point</span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># dividing by (n-1) because of fencepost-counting</span>
</span></span><span style="display:flex;"><span>    sigma_sq <span style="color:#f92672">=</span> T<span style="color:#f92672">/</span>(n<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>)
</span></span><span style="display:flex;"><span>    t <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>linspace(<span style="color:#ae81ff">0</span>, T, n)
</span></span><span style="display:flex;"><span>    norm_sample <span style="color:#f92672">=</span> rng<span style="color:#f92672">.</span>normal(<span style="color:#ae81ff">0</span>, np<span style="color:#f92672">.</span>sqrt(sigma_sq), n<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>)
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># Brownian motion assumed to start at 0 at time t=0</span>
</span></span><span style="display:flex;"><span>    W_t <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>append([<span style="color:#ae81ff">0</span>], norm_sample<span style="color:#f92672">.</span>cumsum())
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> (t, W_t)
</span></span></code></pre></div><p>And then we can simulate a few sample paths and plot them. Note that $T=2$ and $n=1000$. As $n \rightarrow \infty$ the sample path converges to true continous Brownian Motion, these are all discrete approximations.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>t, bm <span style="color:#f92672">=</span> BM_gen(<span style="color:#ae81ff">2</span>, <span style="color:#ae81ff">1000</span>)
</span></span><span style="display:flex;"><span>_, bm2 <span style="color:#f92672">=</span> BM_gen(<span style="color:#ae81ff">2</span>, <span style="color:#ae81ff">1000</span>)
</span></span><span style="display:flex;"><span>_, bm3 <span style="color:#f92672">=</span> BM_gen(<span style="color:#ae81ff">2</span>, <span style="color:#ae81ff">1000</span>)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>plot(t, bm)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>plot(t, bm2)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>plot(t, bm3)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>title(<span style="color:#e6db74">&#34;Brownian Motion Sample Paths&#34;</span>)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>xlabel(<span style="color:#e6db74">&#34;Time&#34;</span>)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>ylabel(<span style="color:#e6db74">&#34;Value&#34;</span>)
</span></span></code></pre></div><figure class="align-center ">
    <img loading="lazy" src="./output_4_1.png#center"/> 
</figure>

<h1 id="geometric-brownian-motion">Geometric Brownian Motion<a hidden class="anchor" aria-hidden="true" href="#geometric-brownian-motion">#</a></h1>
<hr>
<p>Now we move on to what is probably the most widely applied stochastic process, Geometric Brownian Motion:</p>
<blockquote>
<p>$ dX_t = \mu X_t dt + \sigma X_t dW_t $<br>
$X_0 = x_0$</p>
</blockquote>
<p>Using methods of stochastic calculus, one can arrive at the following solution:</p>
<blockquote>
<p>$ X_t = x_0 \exp((\mu - \frac{\sigma^2}{2}) t + \sigma W_t) $.</p>
</blockquote>
<p>Which has expectation</p>
<blockquote>
<p>$E[X_t] = x_0 e^{\mu t}$</p>
</blockquote>
<p>Note one important property of this solution is that it always has the same sign as the initial condition. This makes it useful for modelling stock prices as they need to be always positive.</p>
<p>Because of this simple formula, it&rsquo;s very easy to simulate sample paths of Geometric Brownian Motion once you have a Brownian Motion sample path:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">GBM_gen</span>(x_0, mu, sigma, T, n):
</span></span><span style="display:flex;"><span>    t, W_t <span style="color:#f92672">=</span> BM_gen(T, n)
</span></span><span style="display:flex;"><span>    X_t <span style="color:#f92672">=</span> x_0 <span style="color:#f92672">*</span> np<span style="color:#f92672">.</span>exp((mu <span style="color:#f92672">-</span> sigma<span style="color:#f92672">**</span><span style="color:#ae81ff">2</span><span style="color:#f92672">/</span><span style="color:#ae81ff">2</span>) <span style="color:#f92672">*</span> t <span style="color:#f92672">+</span> sigma <span style="color:#f92672">*</span> W_t)
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> (t, X_t)
</span></span></code></pre></div><p>And then we can again generate some sample paths and plot the expected value function:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>x_0 <span style="color:#f92672">=</span> <span style="color:#ae81ff">1</span>
</span></span><span style="display:flex;"><span>mu <span style="color:#f92672">=</span> <span style="color:#ae81ff">1</span>
</span></span><span style="display:flex;"><span>sigma <span style="color:#f92672">=</span> <span style="color:#ae81ff">0.4</span>
</span></span><span style="display:flex;"><span>t, gbm <span style="color:#f92672">=</span> GBM_gen(x_0, mu, sigma, <span style="color:#ae81ff">2</span>, <span style="color:#ae81ff">1000</span>)
</span></span><span style="display:flex;"><span>_, gbm2 <span style="color:#f92672">=</span> GBM_gen(x_0, mu, sigma, <span style="color:#ae81ff">2</span>, <span style="color:#ae81ff">1000</span>)
</span></span><span style="display:flex;"><span>_, gbm3 <span style="color:#f92672">=</span> GBM_gen(x_0, mu, sigma, <span style="color:#ae81ff">2</span>, <span style="color:#ae81ff">1000</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>plot(t, x_0 <span style="color:#f92672">*</span> np<span style="color:#f92672">.</span>exp(mu <span style="color:#f92672">*</span> t), color<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;black&#34;</span>)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>plot(t, gbm)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>plot(t, gbm2)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>plot(t, gbm3)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>legend([<span style="color:#e6db74">&#34;E(X_t)&#34;</span>])
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>title(<span style="color:#e6db74">&#34;Geometric Brownian Motion Sample Paths&#34;</span>)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>xlabel(<span style="color:#e6db74">&#34;Time&#34;</span>)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>ylabel(<span style="color:#e6db74">&#34;Value&#34;</span>)
</span></span></code></pre></div><figure class="align-center ">
    <img loading="lazy" src="./output_8_1.png#center"/> 
</figure>

<h1 id="the-linear-stochastic-differential-equation">The Linear Stochastic Differential Equation<a hidden class="anchor" aria-hidden="true" href="#the-linear-stochastic-differential-equation">#</a></h1>
<hr>
<p>Next is the Linear SDE:</p>
<blockquote>
<p>$dX_t = \mu X_t dt + \sigma dW_t$<br>
$X_0 = x_0$</p>
</blockquote>
<p>This has the same drift term as GBM, but doesn&rsquo;t scale it&rsquo;s noise by the current value of the process. This has solution</p>
<blockquote>
<p>$ X_t = x_0 e^{\mu t} + \sigma \int_{0}^{t} e^{\mu(t-s)} dW_s $</p>
</blockquote>
<p>With expectation</p>
<blockquote>
<p>$E[X_t] = x_0e^{\mu t} $</p>
</blockquote>
<p>which we expect given the matching drift term to GBM.</p>
<p>This, unlike the GBM solution, includes a stochastic integral which must be estimated. In a similar vein to traditional Riemann–Stieltjes integrals, we can estimate stochastic integrals by</p>
<blockquote>
<p>$ \int_{a}^{b} g_s dW_s = \sum_{k=0}^{n-1} g_{t_k}(W_{t_{k+1}} - W_{t_k}) $</p>
</blockquote>
<p>where $g$ is some arbitrary function or process and each $t_k$ is a time partition like we defined in the section above on Brownian Motion. As $n \rightarrow \infty$ this sum converges to the integral. The function below estimates this sum given a function, a set of times, and a Brownian Motion sample path:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">stoch_int_est</span>(g, t, W_t):
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># W_(t+1) - W_t</span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># Duplicate last difference so that the length of this vector matches t</span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># This is not technically correct, but is good enough</span>
</span></span><span style="display:flex;"><span>    forward_diff <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>append(W_t[<span style="color:#ae81ff">1</span>:] <span style="color:#f92672">-</span> W_t[:<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>], W_t[<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>] <span style="color:#f92672">-</span> W_t[<span style="color:#f92672">-</span><span style="color:#ae81ff">2</span>])
</span></span><span style="display:flex;"><span>    func_vals <span style="color:#f92672">=</span> g(t, t[<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>])
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> (func_vals <span style="color:#f92672">*</span> forward_diff)<span style="color:#f92672">.</span>cumsum()
</span></span></code></pre></div><p>We can test that this function works by estimating a stochastic integral we know the solution to. The integral of Brownian Motion with respect to itself</p>
<blockquote>
<p>$ \int_{0}^{t} W_s dW_s $</p>
</blockquote>
<p>can be shown using Ito&rsquo;s Lemma to have the solution</p>
<blockquote>
<p>$\frac{W_t^2 - t}{2}$</p>
</blockquote>
<p>Below, we plot a Brownian Motion sample path, the known solution of the integral of that path with respect to itself, and the estimate given by the above function:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>t, W_t <span style="color:#f92672">=</span> BM_gen(<span style="color:#ae81ff">2</span>, <span style="color:#ae81ff">1000</span>)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>plot(t, W_t)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>plot(t, stoch_int_est(<span style="color:#66d9ef">lambda</span> s, t: W_t, t, W_t))
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>plot(t, (W_t<span style="color:#f92672">**</span><span style="color:#ae81ff">2</span> <span style="color:#f92672">-</span> t)<span style="color:#f92672">/</span><span style="color:#ae81ff">2</span>)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>legend([<span style="color:#e6db74">&#34;W_t&#34;</span>, <span style="color:#e6db74">&#34;Est&#34;</span>, <span style="color:#e6db74">&#34;Real&#34;</span>])
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>title(<span style="color:#e6db74">&#34;Stochastic Integrals&#34;</span>)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>xlabel(<span style="color:#e6db74">&#34;Time&#34;</span>)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>ylabel(<span style="color:#e6db74">&#34;Value&#34;</span>)
</span></span></code></pre></div><figure class="align-center ">
    <img loading="lazy" src="./output_12_1.png#center"/> 
</figure>

<p>You can see the estimate and the real solutions are quite close to each other, verifying the behavior of our estimation function. As we set $n$ to larger values, the convergence will improve. Now, we can use our estimate of the stochastic integral to create sample paths of the linear SDE:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">linear_sde_gen</span>(x_0, mu, sigma, T, n):
</span></span><span style="display:flex;"><span>    t, W_t <span style="color:#f92672">=</span> BM_gen(T, n)
</span></span><span style="display:flex;"><span>    X_t <span style="color:#f92672">=</span> x_0 <span style="color:#f92672">*</span> np<span style="color:#f92672">.</span>exp(mu <span style="color:#f92672">*</span> t) <span style="color:#f92672">+</span> sigma <span style="color:#f92672">*</span> stoch_int_est(<span style="color:#66d9ef">lambda</span> s, t: np<span style="color:#f92672">.</span>exp(mu <span style="color:#f92672">*</span> (t <span style="color:#f92672">-</span> s)), t, W_t)
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> t, X_t
</span></span></code></pre></div><p>And again we can simulate some sample paths along with their expectation:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>x_0 <span style="color:#f92672">=</span> <span style="color:#ae81ff">1</span>
</span></span><span style="display:flex;"><span>mu <span style="color:#f92672">=</span> <span style="color:#ae81ff">1</span>
</span></span><span style="display:flex;"><span>sigma <span style="color:#f92672">=</span> <span style="color:#ae81ff">0.4</span>
</span></span><span style="display:flex;"><span>t, linear_sde <span style="color:#f92672">=</span> linear_sde_gen(x_0, mu, sigma, <span style="color:#ae81ff">2</span>, <span style="color:#ae81ff">1000</span>)
</span></span><span style="display:flex;"><span>_, linear_sde2 <span style="color:#f92672">=</span> linear_sde_gen(x_0, mu, sigma, <span style="color:#ae81ff">2</span>, <span style="color:#ae81ff">1000</span>)
</span></span><span style="display:flex;"><span>_, linear_sde3 <span style="color:#f92672">=</span> linear_sde_gen(x_0, mu, sigma, <span style="color:#ae81ff">2</span>, <span style="color:#ae81ff">1000</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>plot(t, x_0 <span style="color:#f92672">*</span> np<span style="color:#f92672">.</span>exp(mu <span style="color:#f92672">*</span> t), color<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;black&#34;</span>)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>plot(t, linear_sde)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>plot(t, linear_sde2)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>plot(t, linear_sde3)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>legend([<span style="color:#e6db74">&#34;E(X_t)&#34;</span>])
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>title(<span style="color:#e6db74">&#34;Linear SDE Sample Paths&#34;</span>)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>xlabel(<span style="color:#e6db74">&#34;Time&#34;</span>)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>ylabel(<span style="color:#e6db74">&#34;Value&#34;</span>)
</span></span></code></pre></div><figure class="align-center ">
    <img loading="lazy" src="./output_16_1.png#center"/> 
</figure>

<p>As compared to GBM, we can see that firstly, the values can become negative even with a positive initial condition. Secondly, because the noise doesn&rsquo;t scale with the value of the process, we can see that the noise becomes smaller as time increases.</p>
<h1 id="conclusion">Conclusion<a hidden class="anchor" aria-hidden="true" href="#conclusion">#</a></h1>
<hr>
<p>This was a basic introduction to simulation of stochastic processes along with an example of how to estimate stochastic integrals.</p>
<h1 id="references">References<a hidden class="anchor" aria-hidden="true" href="#references">#</a></h1>
<hr>
<blockquote>
<p>Björk, T. (2020). Arbitrage theory in continuous time. Oxford University Press.</p>
</blockquote>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
      <li><a href="http://eadains.github.io/OptionallyBayesHugo/tags/stochastic-processes/">Stochastic-Processes</a></li>
      <li><a href="http://eadains.github.io/OptionallyBayesHugo/tags/monte-carlo/">Monte-Carlo</a></li>
      <li><a href="http://eadains.github.io/OptionallyBayesHugo/tags/python/">Python</a></li>
    </ul>
  </footer>
</article>
    </main>
    
<footer class="footer">
        <span>&copy; 2024 <a href="http://eadains.github.io/OptionallyBayesHugo/">Optionally Bayes</a></span> · 

    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
</body>

</html>

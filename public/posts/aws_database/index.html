<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>Moving my Data to Amazon Web Services | Optionally Bayes</title>
<meta name="keywords" content="AWS, postgresql, data">
<meta name="description" content="Lessons learned migrating my data to AWS">
<meta name="author" content="Erik Dains">
<link rel="canonical" href="http://eadains.github.io/OptionallyBayesHugo/posts/aws_database/">
<link crossorigin="anonymous" href="/OptionallyBayesHugo/assets/css/stylesheet.bcfc03792d6caa596ec2d6e8f4e36ba32f6840d6e52e04254b294666b3f67ad2.css" integrity="sha256-vPwDeS1sqlluwtbo9ONroy9oQNblLgQlSylGZrP2etI=" rel="preload stylesheet" as="style">
<link rel="icon" href="http://eadains.github.io/OptionallyBayesHugo/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="http://eadains.github.io/OptionallyBayesHugo/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="http://eadains.github.io/OptionallyBayesHugo/favicon-32x32.png">
<link rel="apple-touch-icon" href="http://eadains.github.io/OptionallyBayesHugo/apple-touch-icon.png">
<link rel="mask-icon" href="http://eadains.github.io/OptionallyBayesHugo/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="en" href="http://eadains.github.io/OptionallyBayesHugo/posts/aws_database/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
</noscript>
<script>
    MathJax = {
        tex: {
            inlineMath: [['$', '$'], ['\\(', '\\)']]
        }
    };
</script>
<script type="text/javascript" id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-svg.js">
</script>

  

<meta property="og:title" content="Moving my Data to Amazon Web Services" />
<meta property="og:description" content="Lessons learned migrating my data to AWS" />
<meta property="og:type" content="article" />
<meta property="og:url" content="http://eadains.github.io/OptionallyBayesHugo/posts/aws_database/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2021-08-05T00:00:00+00:00" />
<meta property="article:modified_time" content="2021-08-05T00:00:00+00:00" />

<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Moving my Data to Amazon Web Services"/>
<meta name="twitter:description" content="Lessons learned migrating my data to AWS"/>


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Posts",
      "item": "http://eadains.github.io/OptionallyBayesHugo/posts/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "Moving my Data to Amazon Web Services",
      "item": "http://eadains.github.io/OptionallyBayesHugo/posts/aws_database/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "Moving my Data to Amazon Web Services",
  "name": "Moving my Data to Amazon Web Services",
  "description": "Lessons learned migrating my data to AWS",
  "keywords": [
    "AWS", "postgresql", "data"
  ],
  "articleBody": "I’ve been using a SQLite database to store my financial data locally for a while. This meant I had to have my personal computer running to do updates, I didn’t have a consistent way to access data, and ran the risk of losing my data. I decided it would be best to use Amazon Web Services (AWS) to handle data storage and updating from here on. I learned a lot along the way!\nThings that didn’t work Amazon Aurora Serverless I went in excited about Amazon Aurora Serverless. It seemed perfect for my needs. I don’t need to make database calls very often, so it would automatically shut off and cost nothing after a period of no usage. Great! However, I eventually learned that you cannot connect to an Aurora Serverless instance like you would connect to a normal SQL database to make calls. You have to use the Amazon Data API through the AWS command line interface or through their various SDKs. I frankly didn’t feel like putting the effort in to transition all of my current SQL calls and data handling to this, so I abandoned it.\nI ended up using a normal Relational Database Service instance. I’m using the smallest instance, which only costs about 15 dollars a month and is suitable for my needs.\nAWS Lambda Again, Lambda seemed perfect for my needs. It would run my python code to update my database on a schedule, charge me for that usage, then shut off and cost nothing the rest of the time. However, I found the documentation to be difficult at best and debugging to be challenging.\nYou have to upload your all of your package dependencies with your code in a zip file that ends up being 100’s of megabytes. The size means that you can’t use Amazon’s cloud IDE to update your code, so you have to re-upload it every time you need to change it, and it’s not fast. This made fixing bugs very tedious. You also have to ensure your zip file has certain read/write privileges before you upload it, something that I only found out via Stack Overflow after having errors.\nNext up was scheduling. I need this to run nightly. You have to go through Amazon CloudWatch to do this. Ugh.\nI ended up using an EC2 instance here. The smallest one is part of the free tier, so I don’t even have to pay for it!\nSetup I have found the AWS documentation to be generally hard to get through. Much of it seems to assume that you have background in AWS already, so it’s confusing to start from scratch. I want to document what I did to get this all working.\nVPC AWS creates a virtual network for you to connect all of your instances together. It’s also key to setup properly so you can access your instances from a computer connected via the internet. The easiest way to start is by using the automatic wizard from the dashboard page on the VPC console:\nThen you can select the option for a single public subnet:\nIn the next screen everything can remain the default, and a name for the VPC can be entered. This process automatically creates a VPC, an internet gateway, and a subnet with that gateway attached. We do want to create another subnet under our VPC that is in a different availability zone. This is relevant for the database setup because Amazon puts the backup in a different zone than the database itself. Going to the subnets tab there should be a single subnet under the VPC you created, make note of its availability zone ID. Then you can create a new subnet under that same VPC. The IP block will need to be different. For instance the default subnet will be something like 10.0.0.0/24 so this new subnet will need to be 10.0.1.0/24. Then select an availability zone that is different than the default subnet.\nNext up is the security group that defines what connections will be accepted and from where. Create a new security group under the security heading and make the inbound rules look like this:\nThe two top rules are so other instances in your subnets can connect to your database. The third can be set to accept connections from your personal computers IP by selecting “My IP” in the source box. The fourth has a type of SSH, again from your own IP, this allows you to connect to your EC2 instance via SSH to configure it. For outbound rules you can set destination to 0.0.0.0/0 and everything else to All so everything going out will be allowed.\nNow the networking and security is configured!\nRDS Subnet Group Next we have to make a subnet group for the database to use. In the RDS console, there is a subnet groups link. Create a new one, select the VPC configured earlier, and then select the two subnets. That’s it!\nRDS Instance Now moving to the database instance. Important settings to note:\nThe free tier instance classes are under “Burstable classes” Make sure to deselect Multi-AZ deployment, this costs extra Select the VPC configured earlier under Connectivity, select the subnet group configured earlier, then choose the security group also configured earlier Make sure that public access is set to “yes” Once the instance starts, on its summary page, make note of the endpoint URL and the port. This is the IP and port you’ll use when connecting to the database.\nEC2 Instance You can select a variety of machine images when creating these, I use the Ubuntu Server option. Then you can select the instance type that dictates how many resources the instance has access to. I use the free tier eligible t2.micro. On the configuration page, you can select the VPC, subnet, and other options. When you launch it, you’ll be directed to download a private key file. This is very important to keep. This file allows you to connect to your instance via SSH.\nOnce launched, on the instance summary page, there is the “Public IPv4 DNS.” This is the IP you’ll use to connect to your instance. The SSH command to connect looks like this:\nssh -i [path to .pem file] [Instance IP address] Once in, you can do whatever to get your code where it needs to be to run.\nFor scheduling, I use a cron job to run every night at midnight. Use crontab -e and put a line looking something like this:\n0 0 * * * source ~/RDSDatabase/update.sh Where update.sh is whatever you need to run. Mine looks like this:\n#!/bin/bash cd ~/RDSDatabase source venv/bin/activate python data_update.py Conclusion After all the fuss of figuring this out, it has been very well worth it. My data is there and up-to-date whenever I need it. I’ve created some data classes to fetch and hold the data the way I need it, so I have a consistent way to access it. It all just works. Most importantly, it’s not costing me that much money!\n",
  "wordCount" : "1176",
  "inLanguage": "en",
  "datePublished": "2021-08-05T00:00:00Z",
  "dateModified": "2021-08-05T00:00:00Z",
  "author":{
    "@type": "Person",
    "name": "Erik Dains"
  },
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "http://eadains.github.io/OptionallyBayesHugo/posts/aws_database/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Optionally Bayes",
    "logo": {
      "@type": "ImageObject",
      "url": "http://eadains.github.io/OptionallyBayesHugo/favicon.ico"
    }
  }
}
</script>
</head>

<body class="" id="top">

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="http://eadains.github.io/OptionallyBayesHugo/" accesskey="h" title="Optionally Bayes (Alt + H)">Optionally Bayes</a>
            <div class="logo-switches">
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="http://eadains.github.io/OptionallyBayesHugo/posts/" title="Posts">
                    <span>Posts</span>
                </a>
            </li>
            <li>
                <a href="http://eadains.github.io/OptionallyBayesHugo/tags/" title="Tags">
                    <span>Tags</span>
                </a>
            </li>
            <li>
                <a href="http://eadains.github.io/OptionallyBayesHugo/archives/" title="Archive">
                    <span>Archive</span>
                </a>
            </li>
            <li>
                <a href="http://eadains.github.io/OptionallyBayesHugo/search/" title="Search (Alt &#43; /)" accesskey=/>
                    <span>Search</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    
    <h1 class="post-title entry-hint-parent">
      Moving my Data to Amazon Web Services
    </h1>
    <div class="post-meta"><span title='2021-08-05 00:00:00 +0000 UTC'>August 5, 2021</span>&nbsp;·&nbsp;Erik Dains

</div>
  </header> 
  <div class="post-content"><p>I&rsquo;ve been using a SQLite database to store my financial data locally for a while. This meant I had to have my personal computer running to do updates, I didn&rsquo;t have a consistent way to access data, and ran the risk of losing my data. I decided it would be best to use Amazon Web Services (AWS) to handle data storage and updating from here on. I learned a lot along the way!</p>
<h1 id="things-that-didnt-work">Things that didn&rsquo;t work<a hidden class="anchor" aria-hidden="true" href="#things-that-didnt-work">#</a></h1>
<h3 id="amazon-aurora-serverless">Amazon Aurora Serverless<a hidden class="anchor" aria-hidden="true" href="#amazon-aurora-serverless">#</a></h3>
<p>I went in excited about <a href="https://aws.amazon.com/rds/aurora/serverless/">Amazon Aurora Serverless</a>. It seemed perfect for my needs. I don&rsquo;t need to make database calls very often, so it would automatically shut off and cost nothing after a period of no usage. Great! However, I eventually learned that you cannot connect to an Aurora Serverless instance like you would connect to a normal SQL database to make calls. You have to use the <a href="https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/data-api.html">Amazon Data API</a> through the AWS command line interface or through their various SDKs. I frankly didn&rsquo;t feel like putting the effort in to transition all of my current SQL calls and data handling to this, so I abandoned it.</p>
<p>I ended up using a normal <a href="https://aws.amazon.com/rds/">Relational Database Service</a> instance. I&rsquo;m using the smallest instance, which only costs about 15 dollars a month and is suitable for my needs.</p>
<h3 id="aws-lambda">AWS Lambda<a hidden class="anchor" aria-hidden="true" href="#aws-lambda">#</a></h3>
<p>Again, <a href="https://aws.amazon.com/lambda/">Lambda</a> seemed perfect for my needs. It would run my python code to update my database on a schedule, charge me for that usage, then shut off and cost nothing the rest of the time. However, I found the documentation to be difficult at best and debugging to be challenging.</p>
<p>You have to upload your all of your package dependencies with your code in a zip file that ends up being 100&rsquo;s of megabytes. The size means that you can&rsquo;t use Amazon&rsquo;s cloud IDE to update your code, so you have to re-upload it every time you need to change it, and it&rsquo;s not fast. This made fixing bugs very tedious. You also have to ensure your zip file has certain read/write privileges before you upload it, something that I only found out via Stack Overflow after having errors.</p>
<p>Next up was scheduling. I need this to run nightly. You have to go through <a href="https://docs.aws.amazon.com/AmazonCloudWatch/latest/events/RunLambdaSchedule.html">Amazon CloudWatch</a> to do this. Ugh.</p>
<p>I ended up using an <a href="https://aws.amazon.com/ec2/">EC2</a> instance here. The smallest one is part of the free tier, so I don&rsquo;t even have to pay for it!</p>
<h1 id="setup">Setup<a hidden class="anchor" aria-hidden="true" href="#setup">#</a></h1>
<p>I have found the AWS documentation to be generally hard to get through. Much of it seems to assume that you have background in AWS already, so it&rsquo;s confusing to start from scratch. I want to document what I did to get this all working.</p>
<h3 id="vpc">VPC<a hidden class="anchor" aria-hidden="true" href="#vpc">#</a></h3>
<p>AWS creates a virtual network for you to connect all of your instances together. It&rsquo;s also key to setup properly so you can access your instances from a computer connected via the internet. The easiest way to start is by using the automatic wizard from the dashboard page on the VPC console:</p>
<figure class="align-center ">
    <img loading="lazy" src="./vpc_1.png#center"/> 
</figure>

<p>Then you can select the option for a single public subnet:</p>
<figure class="align-center ">
    <img loading="lazy" src="./vpc_2.png#center"/> 
</figure>

<p>In the next screen everything can remain the default, and a name for the VPC can be entered. This process automatically creates a VPC, an internet gateway, and a subnet with that gateway attached. We do want to create another subnet under our VPC that is in a different availability zone. This is relevant for the database setup because Amazon puts the backup in a different zone than the database itself. Going to the subnets tab there should be a single subnet under the VPC you created, make note of its availability zone ID. Then you can create a new subnet under that same VPC. The IP block will need to be different. For instance the default subnet will be something like 10.0.0.0/24 so this new subnet will need to be 10.0.1.0/24. Then select an availability zone that is different than the default subnet.</p>
<p>Next up is the security group that defines what connections will be accepted and from where. Create a new security group under the security heading and make the inbound rules look like this:</p>
<figure class="align-center ">
    <img loading="lazy" src="./security_group_setup_1.png#center"/> 
</figure>

<p>The two top rules are so other instances in your subnets can connect to your database. The third can be set to accept connections from your personal computers IP by selecting &ldquo;My IP&rdquo; in the source box. The fourth has a type of SSH, again from your own IP, this allows you to connect to your EC2 instance via SSH to configure it. For outbound rules you can set destination to 0.0.0.0/0 and everything else to All so everything going out will be allowed.</p>
<p>Now the networking and security is configured!</p>
<h3 id="rds-subnet-group">RDS Subnet Group<a hidden class="anchor" aria-hidden="true" href="#rds-subnet-group">#</a></h3>
<p>Next we have to make a subnet group for the database to use. In the RDS console, there is a subnet groups link. Create a new one, select the VPC configured earlier, and then select the two subnets. That&rsquo;s it!</p>
<h3 id="rds-instance">RDS Instance<a hidden class="anchor" aria-hidden="true" href="#rds-instance">#</a></h3>
<p>Now moving to the database instance. Important settings to note:</p>
<ul>
<li>The free tier instance classes are under &ldquo;Burstable classes&rdquo;</li>
<li>Make sure to deselect Multi-AZ deployment, this costs extra</li>
<li>Select the VPC configured earlier under Connectivity, select the subnet group configured earlier, then choose the security group also configured earlier</li>
<li><strong>Make sure that public access is set to &ldquo;yes&rdquo;</strong></li>
</ul>
<p>Once the instance starts, on its summary page, make note of the endpoint URL and the port. This is the IP and port you&rsquo;ll use when connecting to the database.</p>
<h3 id="ec2-instance">EC2 Instance<a hidden class="anchor" aria-hidden="true" href="#ec2-instance">#</a></h3>
<p>You can select a variety of machine images when creating these, I use the Ubuntu Server option. Then you can select the instance type that dictates how many resources the instance has access to. I use the free tier eligible t2.micro. On the configuration page, you can select the VPC, subnet, and other options. When you launch it, you&rsquo;ll be directed to download a private key file. <strong>This is very important to keep.</strong> This file allows you to connect to your instance via SSH.</p>
<p>Once launched, on the instance summary page, there is the &ldquo;Public IPv4 DNS.&rdquo; This is the IP you&rsquo;ll use to connect to your instance. The SSH command to connect looks like this:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>ssh -i <span style="color:#f92672">[</span>path to .pem file<span style="color:#f92672">]</span> <span style="color:#f92672">[</span>Instance IP address<span style="color:#f92672">]</span>
</span></span></code></pre></div><p>Once in, you can do whatever to get your code where it needs to be to run.</p>
<p>For scheduling, I use a cron job to run every night at midnight. Use <code>crontab -e</code> and put a line looking something like this:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span><span style="color:#ae81ff">0</span> <span style="color:#ae81ff">0</span> * * * source ~/RDSDatabase/update.sh
</span></span></code></pre></div><p>Where update.sh is whatever you need to run. Mine looks like this:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span><span style="color:#75715e">#!/bin/bash
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>cd ~/RDSDatabase
</span></span><span style="display:flex;"><span>source venv/bin/activate
</span></span><span style="display:flex;"><span>python data_update.py
</span></span></code></pre></div><h1 id="conclusion">Conclusion<a hidden class="anchor" aria-hidden="true" href="#conclusion">#</a></h1>
<p>After all the fuss of figuring this out, it has been very well worth it. My data is there and up-to-date whenever I need it. I&rsquo;ve created some data classes to fetch and hold the data the way I need it, so I have a consistent way to access it. It all <em>just works</em>. Most importantly, it&rsquo;s not costing me that much money!</p>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
      <li><a href="http://eadains.github.io/OptionallyBayesHugo/tags/aws/">AWS</a></li>
      <li><a href="http://eadains.github.io/OptionallyBayesHugo/tags/postgresql/">Postgresql</a></li>
      <li><a href="http://eadains.github.io/OptionallyBayesHugo/tags/data/">Data</a></li>
    </ul>
  </footer>
</article>
    </main>
    
<footer class="footer">
        <span>&copy; 2024 <a href="http://eadains.github.io/OptionallyBayesHugo/">Optionally Bayes</a></span> · 

    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
</body>

</html>
